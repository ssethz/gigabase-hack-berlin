#!/bin/bash
#SBATCH --job-name=rfdiff_15pgdh
#SBATCH --time=01:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=12G
#SBATCH --gpus=nvidia_geforce_rtx_4090:1
#SBATCH --output=logs/rfdiff_%A_%a.out
#SBATCH --error=logs/rfdiff_%A_%a.err

# Run RFdiffusion DARPin partial diffusion for 15-PGDH interface binder design.
#
# Supports SLURM job arrays: submit with --array=0-(N-1) to parallelize
# across N GPUs, each generating 1 design.
#
# Usage:
#   sbatch --array=0-9 scripts/run_rfdiffusion.sh [partial_T]
#   sbatch scripts/run_rfdiffusion.sh [partial_T]   # single design (no array)
#
# Scaffold: 2XEH NI3C Mut6 DARPin (157 residues, chain B)
# Target: 15-PGDH chain A, residues 0-265 (266 residues)
# Strategy: Fix target + DARPin helices, diffuse only binding loops
# Hotspots: alpha-9 helix region (A143, A144, A165)

set -euo pipefail

export PGDH_ROOT="/cluster/home/csageder/gigabase-hack-berlin"
source "${PGDH_ROOT}/scripts/setup_env.sh"

PARTIAL_T="${1:-15}"
TASK_ID="${SLURM_ARRAY_TASK_ID:-0}"

module load eth_proxy
module load stack/2024-06 gcc/12.2.0
module load cuda/12.8.0

# RFdiffusion dependencies (including DGL) are in SE3nv.
set +u
source "${STRUCT_CONDA_BASE}/bin/activate" "${RFDIFF_CONDA_ENV}"
set -u

# Ensure RFdiffusion package is importable when running from source checkout.
export PYTHONPATH="${RFDIFF_DIR}:${PYTHONPATH:-}"

echo "=== GPU preflight ==="
nvidia-smi -L
python - <<'PY'
import sys
from pathlib import Path
import torch
print(f"torch={torch.__version__}")
print(f"torch.version.cuda={torch.version.cuda}")
print(f"cuda_available={torch.cuda.is_available()}")
if (torch.version.cuda is None) or (not torch.cuda.is_available()):
    print("ERROR: CUDA-enabled PyTorch not available in this job environment.", file=sys.stderr)
    sys.exit(1)
print(f"gpu_count={torch.cuda.device_count()}")
print(f"gpu_name={torch.cuda.get_device_name(0)}")

try:
    import rfdiffusion  # noqa: F401
except Exception as e:
    print(f"ERROR: Cannot import rfdiffusion in current env: {e}", file=sys.stderr)
    sys.exit(1)

try:
    import dgl  # noqa: F401
except Exception as e:
    print(f"ERROR: Cannot import dgl in current env: {e}", file=sys.stderr)
    sys.exit(1)

rfdiff_dir = Path("/cluster/home/csageder/RFdiffusion")
required = [
    rfdiff_dir / "scripts" / "run_inference.py",
    rfdiff_dir / "models" / "Complex_base_ckpt.pt",
]
missing = [str(p) for p in required if not p.exists()]
if missing:
    print("ERROR: Missing required RFdiffusion files:", file=sys.stderr)
    for p in missing:
        print(f"  - {p}", file=sys.stderr)
    sys.exit(1)
PY

cd "${RFDIFF_DIR}"

DARPIN_COMPLEX="${PGDH_ROOT}/targets/darpin_on_15pgdh.pdb"

# Source params generated by prepare_darpin.py (inpaint_str, hotspots, contigs)
RFDIFF_PARAMS="${PGDH_ROOT}/targets/rfdiff_params.sh"
if [ -f "${RFDIFF_PARAMS}" ]; then
    source "${RFDIFF_PARAMS}"
else
    echo "WARNING: ${RFDIFF_PARAMS} not found, using defaults. Run 'bash run_pipeline.sh prepare' first."
    HOTSPOTS="[A99,A100,A113,A116,A123,A144,A149,A153,A156,A161,A164,A172]"
    INPAINT_STR="[A0-265]"
    CONTIGS="[A0-265/0 B1-157]"
    PROVIDE_SEQ=""
fi

# Use OUTPUT_DIR env var if set by pipeline, otherwise generate timestamp-based path
OUTPUT_PREFIX="${RFDIFF_OUTPUT_DIR:-${PGDH_SCRATCH}/rfdiff/darpin_pT${PARTIAL_T}_$(date +%Y%m%d_%H%M%S)}"

echo "=== RFdiffusion DARPin partial diffusion (2XEH NI3C Mut6) ==="
echo "Input complex: ${DARPIN_COMPLEX}"
echo "Partial T: ${PARTIAL_T}"
echo "Hotspots: ${HOTSPOTS}"
echo "Inpaint:  ${INPAINT_STR}"
echo "Provide seq: ${PROVIDE_SEQ:-none}"
echo "Array task ID: ${TASK_ID}"

if [ ! -f "${DARPIN_COMPLEX}" ]; then
    echo "ERROR: DARPin complex PDB not found: ${DARPIN_COMPLEX}"
    echo "Run 'bash run_pipeline.sh prepare' first."
    exit 1
fi

mkdir -p "${OUTPUT_PREFIX}"
if [ ! -w "${OUTPUT_PREFIX}" ]; then
    echo "ERROR: Output directory is not writable: ${OUTPUT_PREFIX}"
    exit 1
fi

if [ "${PRECHECK_ONLY:-0}" = "1" ]; then
    echo "PRECHECK_ONLY=1 set; RFdiffusion preflight passed."
    exit 0
fi

PROVIDE_SEQ_ARG=""
if [ -n "${PROVIDE_SEQ:-}" ]; then
    PROVIDE_SEQ_ARG="contigmap.provide_seq=${PROVIDE_SEQ}"
fi

python scripts/run_inference.py \
    inference.output_prefix="${OUTPUT_PREFIX}/design_${TASK_ID}" \
    inference.input_pdb="${DARPIN_COMPLEX}" \
    inference.ckpt_override_path="${RFDIFF_DIR}/models/Complex_base_ckpt.pt" \
    "contigmap.contigs=${CONTIGS}" \
    "contigmap.inpaint_str=${INPAINT_STR}" \
    "ppi.hotspot_res=${HOTSPOTS}" \
    diffuser.partial_T="${PARTIAL_T}" \
    inference.num_designs=1 \
    ${PROVIDE_SEQ_ARG:+"${PROVIDE_SEQ_ARG}"}

echo "=== RFdiffusion task ${TASK_ID} complete ==="
echo "Output: ${OUTPUT_PREFIX}"
ls -la "${OUTPUT_PREFIX}"/design_${TASK_ID}*.pdb 2>/dev/null
